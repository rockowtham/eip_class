{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment4b.1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rockowtham/eip_class/blob/class4/Assignment4b_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1WjMmLlKAofw",
        "colab_type": "code",
        "outputId": "e818f1ae-1560-4aa0-e79d-dfa9a345583b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from __future__ import print_function\n",
        "import keras\n",
        "from keras.layers import Dense, Conv2D, BatchNormalization, Activation\n",
        "from keras.layers import AveragePooling2D, Input, Flatten\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.regularizers import l2\n",
        "from keras import backend as K\n",
        "from keras.models import Model\n",
        "from keras.datasets import cifar10\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# Training parameters\n",
        "batch_size = 128  # orig paper trained all networks with batch_size=128\n",
        "epochs = 50\n",
        "data_augmentation = True\n",
        "num_classes = 10\n",
        "\n",
        "# Subtracting pixel mean improves accuracy\n",
        "subtract_pixel_mean = True\n",
        "\n",
        "# Model parameter\n",
        "# ----------------------------------------------------------------------------\n",
        "#           |      | 200-epoch | Orig Paper| 200-epoch | Orig Paper| sec/epoch\n",
        "# Model     |  n   | ResNet v1 | ResNet v1 | ResNet v2 | ResNet v2 | GTX1080Ti\n",
        "#           |v1(v2)| %Accuracy | %Accuracy | %Accuracy | %Accuracy | v1 (v2)\n",
        "# ----------------------------------------------------------------------------\n",
        "# ResNet20  | 3 (2)| 92.16     | 91.25     | -----     | -----     | 35 (---)\n",
        "# ResNet32  | 5(NA)| 92.46     | 92.49     | NA        | NA        | 50 ( NA)\n",
        "# ResNet44  | 7(NA)| 92.50     | 92.83     | NA        | NA        | 70 ( NA)\n",
        "# ResNet56  | 9 (6)| 92.71     | 93.03     | 93.01     | NA        | 90 (100)\n",
        "# ResNet110 |18(12)| 92.65     | 93.39+-.16| 93.15     | 93.63     | 165(180)\n",
        "# ResNet164 |27(18)| -----     | 94.07     | -----     | 94.54     | ---(---)\n",
        "# ResNet1001| (111)| -----     | 92.39     | -----     | 95.08+-.14| ---(---)\n",
        "# ---------------------------------------------------------------------------\n",
        "n = 3\n",
        "\n",
        "# Model version\n",
        "# Orig paper: version = 1 (ResNet v1), Improved ResNet: version = 2 (ResNet v2)\n",
        "version = 1\n",
        "\n",
        "# Computed depth from supplied model parameter n\n",
        "if version == 1:\n",
        "    depth = n * 6 + 2\n",
        "elif version == 2:\n",
        "    depth = n * 9 + 2\n",
        "\n",
        "# Model name, depth and version\n",
        "model_type = 'ResNet%dv%d' % (depth, version)\n",
        "\n",
        "# Load the CIFAR10 data.\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# Input image dimensions.\n",
        "input_shape = x_train.shape[1:]\n",
        "\n",
        "# Normalize data.\n",
        "x_train = x_train.astype('float32') / 255\n",
        "x_test = x_test.astype('float32') / 255\n",
        "\n",
        "# If subtract pixel mean is enabled\n",
        "if subtract_pixel_mean:\n",
        "    x_train_mean = np.mean(x_train, axis=0)\n",
        "    x_train -= x_train_mean\n",
        "    x_test -= x_train_mean\n",
        "\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "print('y_train shape:', y_train.shape)\n",
        "\n",
        "# Convert class vectors to binary class matrices.\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "\n",
        "def lr_schedule(epoch):\n",
        "    \"\"\"Learning Rate Schedule\n",
        "\n",
        "    Learning rate is scheduled to be reduced after 80, 120, 160, 180 epochs.\n",
        "    Called automatically every epoch as part of callbacks during training.\n",
        "\n",
        "    # Arguments\n",
        "        epoch (int): The number of epochs\n",
        "\n",
        "    # Returns\n",
        "        lr (float32): learning rate\n",
        "    \"\"\"\n",
        "    lr = 1e-3\n",
        "    if epoch > 180:\n",
        "        lr *= 0.5e-3\n",
        "    elif epoch > 160:\n",
        "        lr *= 1e-3\n",
        "    elif epoch > 120:\n",
        "        lr *= 1e-2\n",
        "    elif epoch > 40:\n",
        "        lr *= 1e-1\n",
        "    print('Learning rate: ', lr)\n",
        "    return lr\n",
        "\n",
        "\n",
        "def resnet_layer(inputs,\n",
        "                 num_filters=16,\n",
        "                 kernel_size=3,\n",
        "                 strides=1,\n",
        "                 activation='relu',\n",
        "                 batch_normalization=True,\n",
        "                 conv_first=True):\n",
        "    \"\"\"2D Convolution-Batch Normalization-Activation stack builder\n",
        "\n",
        "    # Arguments\n",
        "        inputs (tensor): input tensor from input image or previous layer\n",
        "        num_filters (int): Conv2D number of filters\n",
        "        kernel_size (int): Conv2D square kernel dimensions\n",
        "        strides (int): Conv2D square stride dimensions\n",
        "        activation (string): activation name\n",
        "        batch_normalization (bool): whether to include batch normalization\n",
        "        conv_first (bool): conv-bn-activation (True) or\n",
        "            bn-activation-conv (False)\n",
        "\n",
        "    # Returns\n",
        "        x (tensor): tensor as input to the next layer\n",
        "    \"\"\"\n",
        "    conv = Conv2D(num_filters,\n",
        "                  kernel_size=kernel_size,\n",
        "                  strides=strides,\n",
        "                  padding='same',\n",
        "                  kernel_initializer='he_normal',\n",
        "                  kernel_regularizer=l2(1e-4))\n",
        "\n",
        "    x = inputs\n",
        "    if conv_first:\n",
        "        x = conv(x)\n",
        "        if batch_normalization:\n",
        "            x = BatchNormalization()(x)\n",
        "        if activation is not None:\n",
        "            x = Activation(activation)(x)\n",
        "    else:\n",
        "        if batch_normalization:\n",
        "            x = BatchNormalization()(x)\n",
        "        if activation is not None:\n",
        "            x = Activation(activation)(x)\n",
        "        x = conv(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "def resnet_v1(input_shape, depth, num_classes=10):\n",
        "    \"\"\"ResNet Version 1 Model builder [a]\n",
        "\n",
        "    Stacks of 2 x (3 x 3) Conv2D-BN-ReLU\n",
        "    Last ReLU is after the shortcut connection.\n",
        "    At the beginning of each stage, the feature map size is halved (downsampled)\n",
        "    by a convolutional layer with strides=2, while the number of filters is\n",
        "    doubled. Within each stage, the layers have the same number filters and the\n",
        "    same number of filters.\n",
        "    Features maps sizes:\n",
        "    stage 0: 32x32, 16\n",
        "    stage 1: 16x16, 32\n",
        "    stage 2:  8x8,  64\n",
        "    The Number of parameters is approx the same as Table 6 of [a]:\n",
        "    ResNet20 0.27M\n",
        "    ResNet32 0.46M\n",
        "    ResNet44 0.66M\n",
        "    ResNet56 0.85M\n",
        "    ResNet110 1.7M\n",
        "\n",
        "    # Arguments\n",
        "        input_shape (tensor): shape of input image tensor\n",
        "        depth (int): number of core convolutional layers\n",
        "        num_classes (int): number of classes (CIFAR10 has 10)\n",
        "\n",
        "    # Returns\n",
        "        model (Model): Keras model instance\n",
        "    \"\"\"\n",
        "    if (depth - 2) % 6 != 0:\n",
        "        raise ValueError('depth should be 6n+2 (eg 20, 32, 44 in [a])')\n",
        "    # Start model definition.\n",
        "    num_filters = 16\n",
        "    num_res_blocks = int((depth - 2) / 6)\n",
        "\n",
        "    inputs = Input(shape=input_shape)\n",
        "    x = resnet_layer(inputs=inputs)\n",
        "    # Instantiate the stack of residual units\n",
        "    for stack in range(3):\n",
        "        for res_block in range(num_res_blocks):\n",
        "            strides = 1\n",
        "            if stack > 0 and res_block == 0:  # first layer but not first stack\n",
        "                strides = 2  # downsample\n",
        "            y = resnet_layer(inputs=x,\n",
        "                             num_filters=num_filters,\n",
        "                             strides=strides)\n",
        "            y = resnet_layer(inputs=y,\n",
        "                             num_filters=num_filters,\n",
        "                             activation=None)\n",
        "            if stack > 0 and res_block == 0:  # first layer but not first stack\n",
        "                # linear projection residual shortcut connection to match\n",
        "                # changed dims\n",
        "                x = resnet_layer(inputs=x,\n",
        "                                 num_filters=num_filters,\n",
        "                                 kernel_size=1,\n",
        "                                 strides=strides,\n",
        "                                 activation=None,\n",
        "                                 batch_normalization=False)\n",
        "            x = keras.layers.add([x, y])\n",
        "            x = Activation('relu')(x)\n",
        "        num_filters *= 2\n",
        "\n",
        "    # Add classifier on top.\n",
        "    # v1 does not use BN after last shortcut connection-ReLU\n",
        "    x = AveragePooling2D(pool_size=8)(x)\n",
        "    y = Flatten()(x)\n",
        "    outputs = Dense(num_classes,\n",
        "                    activation='softmax',\n",
        "                    kernel_initializer='he_normal')(y)\n",
        "\n",
        "    # Instantiate model.\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    return model\n",
        "\n",
        "\n",
        "def resnet_v2(input_shape, depth, num_classes=10):\n",
        "    \"\"\"ResNet Version 2 Model builder [b]\n",
        "\n",
        "    Stacks of (1 x 1)-(3 x 3)-(1 x 1) BN-ReLU-Conv2D or also known as\n",
        "    bottleneck layer\n",
        "    First shortcut connection per layer is 1 x 1 Conv2D.\n",
        "    Second and onwards shortcut connection is identity.\n",
        "    At the beginning of each stage, the feature map size is halved (downsampled)\n",
        "    by a convolutional layer with strides=2, while the number of filter maps is\n",
        "    doubled. Within each stage, the layers have the same number filters and the\n",
        "    same filter map sizes.\n",
        "    Features maps sizes:\n",
        "    conv1  : 32x32,  16\n",
        "    stage 0: 32x32,  64\n",
        "    stage 1: 16x16, 128\n",
        "    stage 2:  8x8,  256\n",
        "\n",
        "    # Arguments\n",
        "        input_shape (tensor): shape of input image tensor\n",
        "        depth (int): number of core convolutional layers\n",
        "        num_classes (int): number of classes (CIFAR10 has 10)\n",
        "\n",
        "    # Returns\n",
        "        model (Model): Keras model instance\n",
        "    \"\"\"\n",
        "    if (depth - 2) % 9 != 0:\n",
        "        raise ValueError('depth should be 9n+2 (eg 56 or 110 in [b])')\n",
        "    # Start model definition.\n",
        "    num_filters_in = 16\n",
        "    num_res_blocks = int((depth - 2) / 9)\n",
        "\n",
        "    inputs = Input(shape=input_shape)\n",
        "    # v2 performs Conv2D with BN-ReLU on input before splitting into 2 paths\n",
        "    x = resnet_layer(inputs=inputs,\n",
        "                     num_filters=num_filters_in,\n",
        "                     conv_first=True)\n",
        "\n",
        "    # Instantiate the stack of residual units\n",
        "    for stage in range(3):\n",
        "        for res_block in range(num_res_blocks):\n",
        "            activation = 'relu'\n",
        "            batch_normalization = True\n",
        "            strides = 1\n",
        "            if stage == 0:\n",
        "                num_filters_out = num_filters_in * 4\n",
        "                if res_block == 0:  # first layer and first stage\n",
        "                    activation = None\n",
        "                    batch_normalization = False\n",
        "            else:\n",
        "                num_filters_out = num_filters_in * 2\n",
        "                if res_block == 0:  # first layer but not first stage\n",
        "                    strides = 2    # downsample\n",
        "\n",
        "            # bottleneck residual unit\n",
        "            y = resnet_layer(inputs=x,\n",
        "                             num_filters=num_filters_in,\n",
        "                             kernel_size=1,\n",
        "                             strides=strides,\n",
        "                             activation=activation,\n",
        "                             batch_normalization=batch_normalization,\n",
        "                             conv_first=False)\n",
        "            y = resnet_layer(inputs=y,\n",
        "                             num_filters=num_filters_in,\n",
        "                             conv_first=False)\n",
        "            y = resnet_layer(inputs=y,\n",
        "                             num_filters=num_filters_out,\n",
        "                             kernel_size=1,\n",
        "                             conv_first=False)\n",
        "            if res_block == 0:\n",
        "                # linear projection residual shortcut connection to match\n",
        "                # changed dims\n",
        "                x = resnet_layer(inputs=x,\n",
        "                                 num_filters=num_filters_out,\n",
        "                                 kernel_size=1,\n",
        "                                 strides=strides,\n",
        "                                 activation=None,\n",
        "                                 batch_normalization=False)\n",
        "            x = keras.layers.add([x, y])\n",
        "\n",
        "        num_filters_in = num_filters_out\n",
        "\n",
        "    # Add classifier on top.\n",
        "    # v2 has BN-ReLU before Pooling\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = AveragePooling2D(pool_size=8)(x)\n",
        "    y = Flatten()(x)\n",
        "    outputs = Dense(num_classes,\n",
        "                    activation='softmax',\n",
        "                    kernel_initializer='he_normal')(y)\n",
        "\n",
        "    # Instantiate model.\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    return model\n",
        "\n",
        "\n",
        "if version == 2:\n",
        "    model = resnet_v2(input_shape=input_shape, depth=depth)\n",
        "else:\n",
        "    model = resnet_v1(input_shape=input_shape, depth=depth)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=Adam(lr=lr_schedule(0)),\n",
        "              metrics=['accuracy'])\n",
        "model.summary()\n",
        "print(model_type)\n",
        "\n",
        "# Prepare model model saving directory.\n",
        "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
        "model_name = 'cifar10_%s_model.{epoch:03d}.h5' % model_type\n",
        "if not os.path.isdir(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "filepath = os.path.join(save_dir, model_name)\n",
        "\n",
        "# Prepare callbacks for model saving and for learning rate adjustment.\n",
        "checkpoint = ModelCheckpoint(filepath=filepath,\n",
        "                             monitor='val_acc',\n",
        "                             verbose=1,\n",
        "                             save_best_only=True)\n",
        "\n",
        "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
        "\n",
        "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),\n",
        "                               cooldown=0,\n",
        "                               patience=5,\n",
        "                               min_lr=0.5e-6)\n",
        "\n",
        "callbacks = [checkpoint, lr_reducer, lr_scheduler]\n",
        "\n",
        "# Run training, with or without data augmentation.\n",
        "if not data_augmentation:\n",
        "    print('Not using data augmentation.')\n",
        "    model.fit(x_train, y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=epochs,\n",
        "              validation_data=(x_test, y_test),\n",
        "              shuffle=True,\n",
        "              callbacks=callbacks)\n",
        "else:\n",
        "    print('Using real-time data augmentation.')\n",
        "    # This will do preprocessing and realtime data augmentation:\n",
        "    datagen = ImageDataGenerator(\n",
        "        # set input mean to 0 over the dataset\n",
        "        featurewise_center=False,\n",
        "        # set each sample mean to 0\n",
        "        samplewise_center=False,\n",
        "        # divide inputs by std of dataset\n",
        "        featurewise_std_normalization=False,\n",
        "        # divide each input by its std\n",
        "        samplewise_std_normalization=False,\n",
        "        # apply ZCA whitening\n",
        "        zca_whitening=False,\n",
        "        # epsilon for ZCA whitening\n",
        "        zca_epsilon=1e-06,\n",
        "        # randomly rotate images in the range (deg 0 to 180)\n",
        "        rotation_range=0,\n",
        "        # randomly shift images horizontally\n",
        "        width_shift_range=0.1,\n",
        "        # randomly shift images vertically\n",
        "        height_shift_range=0.1,\n",
        "        # set range for random shear\n",
        "        shear_range=0.,\n",
        "        # set range for random zoom\n",
        "        zoom_range=0.,\n",
        "        # set range for random channel shifts\n",
        "        channel_shift_range=0.,\n",
        "        # set mode for filling points outside the input boundaries\n",
        "        fill_mode='nearest',\n",
        "        # value used for fill_mode = \"constant\"\n",
        "        cval=0.,\n",
        "        # randomly flip images\n",
        "        horizontal_flip=True,\n",
        "        # randomly flip images\n",
        "        vertical_flip=False,\n",
        "        # set rescaling factor (applied before any other transformation)\n",
        "        rescale=None,\n",
        "        # set function that will be applied on each input\n",
        "        preprocessing_function=None,\n",
        "        # image data format, either \"channels_first\" or \"channels_last\"\n",
        "        data_format=None,\n",
        "        # fraction of images reserved for validation (strictly between 0 and 1)\n",
        "        validation_split=0.0)\n",
        "\n",
        "    # Compute quantities required for featurewise normalization\n",
        "    # (std, mean, and principal components if ZCA whitening is applied).\n",
        "    datagen.fit(x_train)\n",
        "\n",
        "    # Fit the model on the batches generated by datagen.flow().\n",
        "    model_info = model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
        "                        validation_data=(x_test, y_test),\n",
        "                        epochs=epochs, verbose=2, workers=4,\n",
        "                        callbacks=callbacks)\n",
        "\n",
        "# Score trained model.\n",
        "scores = model.evaluate(x_test, y_test, verbose=2)\n",
        "print('Test loss:', scores[0])\n",
        "print('Test accuracy:', scores[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (50000, 32, 32, 3)\n",
            "50000 train samples\n",
            "10000 test samples\n",
            "y_train shape: (50000, 1)\n",
            "Learning rate:  0.001\n",
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 32, 32, 16)   448         input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 32, 32, 16)   64          conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 32, 32, 16)   0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 32, 32, 16)   2320        activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 32, 32, 16)   64          conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 32, 32, 16)   0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 32, 32, 16)   2320        activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 32, 32, 16)   64          conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, 32, 32, 16)   0           activation_20[0][0]              \n",
            "                                                                 batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 32, 32, 16)   0           add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 32, 32, 16)   2320        activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 32, 32, 16)   64          conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 32, 32, 16)   0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 32, 32, 16)   2320        activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 32, 32, 16)   64          conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, 32, 32, 16)   0           activation_22[0][0]              \n",
            "                                                                 batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 32, 32, 16)   0           add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 32, 32, 16)   2320        activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 32, 32, 16)   64          conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 32, 32, 16)   0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 32, 32, 16)   2320        activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 32, 32, 16)   64          conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_12 (Add)                    (None, 32, 32, 16)   0           activation_24[0][0]              \n",
            "                                                                 batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 32, 32, 16)   0           add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 16, 16, 32)   4640        activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 16, 16, 32)   128         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 16, 16, 32)   0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 16, 16, 32)   9248        activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 16, 16, 32)   544         activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 16, 16, 32)   128         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_13 (Add)                    (None, 16, 16, 32)   0           conv2d_31[0][0]                  \n",
            "                                                                 batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 16, 16, 32)   0           add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 16, 16, 32)   9248        activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 16, 16, 32)   128         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 16, 16, 32)   0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 16, 16, 32)   9248        activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 16, 16, 32)   128         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_14 (Add)                    (None, 16, 16, 32)   0           activation_28[0][0]              \n",
            "                                                                 batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 16, 16, 32)   0           add_14[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 16, 16, 32)   9248        activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 16, 16, 32)   128         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 16, 16, 32)   0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 16, 16, 32)   9248        activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 16, 16, 32)   128         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_15 (Add)                    (None, 16, 16, 32)   0           activation_30[0][0]              \n",
            "                                                                 batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 16, 16, 32)   0           add_15[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 8, 8, 64)     18496       activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 8, 8, 64)     256         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 8, 8, 64)     0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 8, 8, 64)     36928       activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 8, 8, 64)     2112        activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 8, 8, 64)     256         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_16 (Add)                    (None, 8, 8, 64)     0           conv2d_38[0][0]                  \n",
            "                                                                 batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 8, 8, 64)     0           add_16[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 8, 8, 64)     36928       activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 8, 8, 64)     256         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 8, 8, 64)     0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 8, 8, 64)     36928       activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 8, 8, 64)     256         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_17 (Add)                    (None, 8, 8, 64)     0           activation_34[0][0]              \n",
            "                                                                 batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 8, 8, 64)     0           add_17[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 8, 8, 64)     36928       activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 8, 8, 64)     256         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 8, 8, 64)     0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 8, 8, 64)     36928       activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 8, 8, 64)     256         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_18 (Add)                    (None, 8, 8, 64)     0           activation_36[0][0]              \n",
            "                                                                 batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 8, 8, 64)     0           add_18[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 1, 1, 64)     0           activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten_2 (Flatten)             (None, 64)           0           average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 10)           650         flatten_2[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 274,442\n",
            "Trainable params: 273,066\n",
            "Non-trainable params: 1,376\n",
            "__________________________________________________________________________________________________\n",
            "ResNet20v1\n",
            "Using real-time data augmentation.\n",
            "Epoch 1/50\n",
            "Learning rate:  0.001\n",
            " - 54s - loss: 1.7219 - acc: 0.4364 - val_loss: 1.6561 - val_acc: 0.4583\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.45830, saving model to /content/saved_models/cifar10_ResNet20v1_model.001.h5\n",
            "Epoch 2/50\n",
            "Learning rate:  0.001\n",
            " - 47s - loss: 1.3055 - acc: 0.5876 - val_loss: 1.7336 - val_acc: 0.4853\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.45830 to 0.48530, saving model to /content/saved_models/cifar10_ResNet20v1_model.002.h5\n",
            "Epoch 3/50\n",
            "Learning rate:  0.001\n",
            " - 46s - loss: 1.1264 - acc: 0.6555 - val_loss: 1.4620 - val_acc: 0.5609\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.48530 to 0.56090, saving model to /content/saved_models/cifar10_ResNet20v1_model.003.h5\n",
            "Epoch 4/50\n",
            "Learning rate:  0.001\n",
            " - 46s - loss: 0.9982 - acc: 0.7035 - val_loss: 1.1109 - val_acc: 0.6766\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.56090 to 0.67660, saving model to /content/saved_models/cifar10_ResNet20v1_model.004.h5\n",
            "Epoch 5/50\n",
            "Learning rate:  0.001\n",
            " - 46s - loss: 0.9153 - acc: 0.7333 - val_loss: 1.4331 - val_acc: 0.6022\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.67660\n",
            "Epoch 6/50\n",
            "Learning rate:  0.001\n",
            " - 46s - loss: 0.8448 - acc: 0.7572 - val_loss: 1.1432 - val_acc: 0.6685\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.67660\n",
            "Epoch 7/50\n",
            "Learning rate:  0.001\n",
            " - 45s - loss: 0.8000 - acc: 0.7728 - val_loss: 1.0233 - val_acc: 0.6938\n",
            "\n",
            "Epoch 00007: val_acc improved from 0.67660 to 0.69380, saving model to /content/saved_models/cifar10_ResNet20v1_model.007.h5\n",
            "Epoch 8/50\n",
            "Learning rate:  0.001\n",
            " - 45s - loss: 0.7596 - acc: 0.7873 - val_loss: 1.1925 - val_acc: 0.6446\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.69380\n",
            "Epoch 9/50\n",
            "Learning rate:  0.001\n",
            " - 45s - loss: 0.7266 - acc: 0.7964 - val_loss: 1.1398 - val_acc: 0.6773\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.69380\n",
            "Epoch 10/50\n",
            "Learning rate:  0.001\n",
            " - 45s - loss: 0.6946 - acc: 0.8098 - val_loss: 0.9001 - val_acc: 0.7569\n",
            "\n",
            "Epoch 00010: val_acc improved from 0.69380 to 0.75690, saving model to /content/saved_models/cifar10_ResNet20v1_model.010.h5\n",
            "Epoch 11/50\n",
            "Learning rate:  0.001\n",
            " - 45s - loss: 0.6699 - acc: 0.8188 - val_loss: 1.0278 - val_acc: 0.7267\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.75690\n",
            "Epoch 12/50\n",
            "Learning rate:  0.001\n",
            " - 44s - loss: 0.6461 - acc: 0.8268 - val_loss: 0.7221 - val_acc: 0.8042\n",
            "\n",
            "Epoch 00012: val_acc improved from 0.75690 to 0.80420, saving model to /content/saved_models/cifar10_ResNet20v1_model.012.h5\n",
            "Epoch 13/50\n",
            "Learning rate:  0.001\n",
            " - 44s - loss: 0.6307 - acc: 0.8326 - val_loss: 0.8662 - val_acc: 0.7653\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.80420\n",
            "Epoch 14/50\n",
            "Learning rate:  0.001\n",
            " - 45s - loss: 0.6131 - acc: 0.8386 - val_loss: 1.0878 - val_acc: 0.7060\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.80420\n",
            "Epoch 15/50\n",
            "Learning rate:  0.001\n",
            " - 44s - loss: 0.5930 - acc: 0.8444 - val_loss: 1.1070 - val_acc: 0.7181\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.80420\n",
            "Epoch 16/50\n",
            "Learning rate:  0.001\n",
            " - 44s - loss: 0.5782 - acc: 0.8503 - val_loss: 0.7078 - val_acc: 0.8092\n",
            "\n",
            "Epoch 00016: val_acc improved from 0.80420 to 0.80920, saving model to /content/saved_models/cifar10_ResNet20v1_model.016.h5\n",
            "Epoch 17/50\n",
            "Learning rate:  0.001\n",
            " - 44s - loss: 0.5734 - acc: 0.8506 - val_loss: 0.7680 - val_acc: 0.7971\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.80920\n",
            "Epoch 18/50\n",
            "Learning rate:  0.001\n",
            " - 44s - loss: 0.5584 - acc: 0.8572 - val_loss: 1.0389 - val_acc: 0.7326\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.80920\n",
            "Epoch 19/50\n",
            "Learning rate:  0.001\n",
            " - 44s - loss: 0.5480 - acc: 0.8619 - val_loss: 0.8265 - val_acc: 0.7868\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.80920\n",
            "Epoch 20/50\n",
            "Learning rate:  0.001\n",
            " - 44s - loss: 0.5365 - acc: 0.8639 - val_loss: 0.7353 - val_acc: 0.8100\n",
            "\n",
            "Epoch 00020: val_acc improved from 0.80920 to 0.81000, saving model to /content/saved_models/cifar10_ResNet20v1_model.020.h5\n",
            "Epoch 21/50\n",
            "Learning rate:  0.001\n",
            " - 44s - loss: 0.5206 - acc: 0.8686 - val_loss: 0.6584 - val_acc: 0.8310\n",
            "\n",
            "Epoch 00021: val_acc improved from 0.81000 to 0.83100, saving model to /content/saved_models/cifar10_ResNet20v1_model.021.h5\n",
            "Epoch 22/50\n",
            "Learning rate:  0.001\n",
            " - 44s - loss: 0.5149 - acc: 0.8727 - val_loss: 0.9204 - val_acc: 0.7624\n",
            "\n",
            "Epoch 00022: val_acc did not improve from 0.83100\n",
            "Epoch 23/50\n",
            "Learning rate:  0.001\n",
            " - 43s - loss: 0.5101 - acc: 0.8736 - val_loss: 0.7244 - val_acc: 0.8064\n",
            "\n",
            "Epoch 00023: val_acc did not improve from 0.83100\n",
            "Epoch 24/50\n",
            "Learning rate:  0.001\n",
            " - 44s - loss: 0.5066 - acc: 0.8750 - val_loss: 0.7439 - val_acc: 0.8059\n",
            "\n",
            "Epoch 00024: val_acc did not improve from 0.83100\n",
            "Epoch 25/50\n",
            "Learning rate:  0.001\n",
            " - 44s - loss: 0.4955 - acc: 0.8794 - val_loss: 0.8840 - val_acc: 0.7804\n",
            "\n",
            "Epoch 00025: val_acc did not improve from 0.83100\n",
            "Epoch 26/50\n",
            "Learning rate:  0.001\n",
            " - 44s - loss: 0.4866 - acc: 0.8825 - val_loss: 0.7621 - val_acc: 0.8025\n",
            "\n",
            "Epoch 00026: val_acc did not improve from 0.83100\n",
            "Epoch 27/50\n",
            "Learning rate:  0.001\n",
            " - 43s - loss: 0.4814 - acc: 0.8846 - val_loss: 0.8190 - val_acc: 0.7981\n",
            "\n",
            "Epoch 00027: val_acc did not improve from 0.83100\n",
            "Epoch 28/50\n",
            "Learning rate:  0.001\n",
            " - 43s - loss: 0.4804 - acc: 0.8850 - val_loss: 0.8646 - val_acc: 0.7805\n",
            "\n",
            "Epoch 00028: val_acc did not improve from 0.83100\n",
            "Epoch 29/50\n",
            "Learning rate:  0.001\n",
            " - 44s - loss: 0.4673 - acc: 0.8890 - val_loss: 0.9665 - val_acc: 0.7655\n",
            "\n",
            "Epoch 00029: val_acc did not improve from 0.83100\n",
            "Epoch 30/50\n",
            "Learning rate:  0.001\n",
            " - 44s - loss: 0.4671 - acc: 0.8909 - val_loss: 0.8246 - val_acc: 0.7860\n",
            "\n",
            "Epoch 00030: val_acc did not improve from 0.83100\n",
            "Epoch 31/50\n",
            "Learning rate:  0.001\n",
            " - 44s - loss: 0.4571 - acc: 0.8935 - val_loss: 0.6864 - val_acc: 0.8312\n",
            "\n",
            "Epoch 00031: val_acc improved from 0.83100 to 0.83120, saving model to /content/saved_models/cifar10_ResNet20v1_model.031.h5\n",
            "Epoch 32/50\n",
            "Learning rate:  0.001\n",
            " - 45s - loss: 0.4538 - acc: 0.8936 - val_loss: 0.7415 - val_acc: 0.8193\n",
            "\n",
            "Epoch 00032: val_acc did not improve from 0.83120\n",
            "Epoch 33/50\n",
            "Learning rate:  0.001\n",
            " - 44s - loss: 0.4546 - acc: 0.8945 - val_loss: 0.6536 - val_acc: 0.8348\n",
            "\n",
            "Epoch 00033: val_acc improved from 0.83120 to 0.83480, saving model to /content/saved_models/cifar10_ResNet20v1_model.033.h5\n",
            "Epoch 34/50\n",
            "Learning rate:  0.001\n",
            " - 44s - loss: 0.4476 - acc: 0.8969 - val_loss: 0.8213 - val_acc: 0.8016\n",
            "\n",
            "Epoch 00034: val_acc did not improve from 0.83480\n",
            "Epoch 35/50\n",
            "Learning rate:  0.001\n",
            " - 44s - loss: 0.4413 - acc: 0.8987 - val_loss: 0.7221 - val_acc: 0.8265\n",
            "\n",
            "Epoch 00035: val_acc did not improve from 0.83480\n",
            "Epoch 36/50\n",
            "Learning rate:  0.001\n",
            "\n",
            "Epoch 00036: val_acc improved from 0.83480 to 0.83950, saving model to /content/saved_models/cifar10_ResNet20v1_model.036.h5\n",
            "Epoch 37/50\n",
            "Learning rate:  0.001\n",
            " - 44s - loss: 0.4371 - acc: 0.9019 - val_loss: 0.7485 - val_acc: 0.8166\n",
            "\n",
            "Epoch 00037: val_acc did not improve from 0.83950\n",
            "Epoch 38/50\n",
            "Learning rate:  0.001\n",
            " - 44s - loss: 0.4330 - acc: 0.9013 - val_loss: 0.6771 - val_acc: 0.8379\n",
            "\n",
            "Epoch 00038: val_acc did not improve from 0.83950\n",
            "Epoch 39/50\n",
            "Learning rate:  0.001\n",
            " - 44s - loss: 0.4247 - acc: 0.9050 - val_loss: 0.6275 - val_acc: 0.8491\n",
            "\n",
            "Epoch 00039: val_acc improved from 0.83950 to 0.84910, saving model to /content/saved_models/cifar10_ResNet20v1_model.039.h5\n",
            "Epoch 40/50\n",
            "Learning rate:  0.001\n",
            " - 44s - loss: 0.4248 - acc: 0.9040 - val_loss: 0.7260 - val_acc: 0.8228\n",
            "\n",
            "Epoch 00040: val_acc did not improve from 0.84910\n",
            "Epoch 41/50\n",
            "Learning rate:  0.001\n",
            " - 44s - loss: 0.4279 - acc: 0.9050 - val_loss: 0.7401 - val_acc: 0.8212\n",
            "\n",
            "Epoch 00041: val_acc did not improve from 0.84910\n",
            "Epoch 42/50\n",
            "Learning rate:  0.0001\n",
            " - 43s - loss: 0.3558 - acc: 0.9298 - val_loss: 0.4916 - val_acc: 0.8881\n",
            "\n",
            "Epoch 00042: val_acc improved from 0.84910 to 0.88810, saving model to /content/saved_models/cifar10_ResNet20v1_model.042.h5\n",
            "Epoch 43/50\n",
            "Learning rate:  0.0001\n",
            " - 44s - loss: 0.3280 - acc: 0.9414 - val_loss: 0.4804 - val_acc: 0.8929\n",
            "\n",
            "Epoch 00043: val_acc improved from 0.88810 to 0.89290, saving model to /content/saved_models/cifar10_ResNet20v1_model.043.h5\n",
            "Epoch 44/50\n",
            "Learning rate:  0.0001\n",
            " - 44s - loss: 0.3188 - acc: 0.9426 - val_loss: 0.4952 - val_acc: 0.8878\n",
            "\n",
            "Epoch 00044: val_acc did not improve from 0.89290\n",
            "Epoch 45/50\n",
            "Learning rate:  0.0001\n",
            " - 44s - loss: 0.3122 - acc: 0.9451 - val_loss: 0.4865 - val_acc: 0.8905\n",
            "\n",
            "Epoch 00045: val_acc did not improve from 0.89290\n",
            "Epoch 46/50\n",
            "Learning rate:  0.0001\n",
            " - 45s - loss: 0.3003 - acc: 0.9484 - val_loss: 0.5000 - val_acc: 0.8886\n",
            "\n",
            "Epoch 00046: val_acc did not improve from 0.89290\n",
            "Epoch 47/50\n",
            "Learning rate:  0.0001\n",
            " - 44s - loss: 0.2986 - acc: 0.9492 - val_loss: 0.4833 - val_acc: 0.8932\n",
            "\n",
            "Epoch 00047: val_acc improved from 0.89290 to 0.89320, saving model to /content/saved_models/cifar10_ResNet20v1_model.047.h5\n",
            "Epoch 48/50\n",
            "Learning rate:  0.0001\n",
            " - 44s - loss: 0.2939 - acc: 0.9505 - val_loss: 0.4768 - val_acc: 0.8916\n",
            "\n",
            "Epoch 00048: val_acc did not improve from 0.89320\n",
            "Epoch 49/50\n",
            "Learning rate:  0.0001\n",
            " - 44s - loss: 0.2880 - acc: 0.9522 - val_loss: 0.4878 - val_acc: 0.8887\n",
            "\n",
            "Epoch 00049: val_acc did not improve from 0.89320\n",
            "Epoch 50/50\n",
            "Learning rate:  0.0001\n",
            " - 44s - loss: 0.2829 - acc: 0.9527 - val_loss: 0.4753 - val_acc: 0.8951\n",
            "\n",
            "Epoch 00050: val_acc improved from 0.89320 to 0.89510, saving model to /content/saved_models/cifar10_ResNet20v1_model.050.h5\n",
            "Test loss: 0.4753378746986389\n",
            "Test accuracy: 0.8951\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w4WACg9Z-0VN",
        "colab_type": "code",
        "outputId": "f011619e-306d-469d-d871-01e5c33cf024",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "def plot_model_history(model_history):\n",
        "    fig, axs = plt.subplots(1,2,figsize=(15,5))\n",
        "    # summarize history for accuracy\n",
        "    axs[0].plot(range(1,len(model_history.history['acc'])+1),model_history.history['acc'])\n",
        "    axs[0].plot(range(1,len(model_history.history['val_acc'])+1),model_history.history['val_acc'])\n",
        "    axs[0].set_title('Model Accuracy')\n",
        "    axs[0].set_ylabel('Accuracy')\n",
        "    axs[0].set_xlabel('Epoch')\n",
        "    axs[0].set_xticks(np.arange(1,len(model_history.history['acc'])+1),len(model_history.history['acc'])/10)\n",
        "    axs[0].legend(['train', 'val'], loc='best')\n",
        "    # summarize history for loss\n",
        "    axs[1].plot(range(1,len(model_history.history['loss'])+1),model_history.history['loss'])\n",
        "    axs[1].plot(range(1,len(model_history.history['val_loss'])+1),model_history.history['val_loss'])\n",
        "    axs[1].set_title('Model Loss')\n",
        "    axs[1].set_ylabel('Loss')\n",
        "    axs[1].set_xlabel('Epoch')\n",
        "    axs[1].set_xticks(np.arange(1,len(model_history.history['loss'])+1),len(model_history.history['loss'])/10)\n",
        "    axs[1].legend(['train', 'val'], loc='best')\n",
        "    plt.show()\n",
        "\n",
        "# plot model history\n",
        "plot_model_history(model_info)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3gAAAFNCAYAAABSRs15AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 1080x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}